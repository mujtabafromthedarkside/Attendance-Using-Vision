{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from opencv-python-headless) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepface\n",
      "  Obtaining dependency information for deepface from https://files.pythonhosted.org/packages/9d/c0/daedaa2bf4de379e1831eca70d53d31dd8dfedf5dd183c385ce1d9188801/deepface-0.0.91-py3-none-any.whl.metadata\n",
      "  Using cached deepface-0.0.91-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting requests>=2.27.1 (from deepface)\n",
      "  Obtaining dependency information for requests>=2.27.1 from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: numpy>=1.14.0 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from deepface) (1.26.4)\n",
      "Collecting pandas>=0.23.4 (from deepface)\n",
      "  Obtaining dependency information for pandas>=0.23.4 from https://files.pythonhosted.org/packages/22/a5/a0b255295406ed54269814bc93723cfd1a0da63fb9aaf99e1364f07923e5/pandas-2.2.2-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached pandas-2.2.2-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting gdown>=3.10.1 (from deepface)\n",
      "  Obtaining dependency information for gdown>=3.10.1 from https://files.pythonhosted.org/packages/54/70/e07c381e6488a77094f04c85c9caf1c8008cdc30778f7019bc52e5285ef0/gdown-5.2.0-py3-none-any.whl.metadata\n",
      "  Using cached gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.30.0 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from deepface) (4.66.4)\n",
      "Requirement already satisfied: Pillow>=5.2.0 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from deepface) (10.3.0)\n",
      "Requirement already satisfied: opencv-python>=4.5.5.64 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from deepface) (4.9.0.80)\n",
      "Collecting tensorflow>=1.9.0 (from deepface)\n",
      "  Obtaining dependency information for tensorflow>=1.9.0 from https://files.pythonhosted.org/packages/76/4f/39ddae9fb07b8c039fa5a5f2b6623c6e0564199d82da33fcef62bcf93174/tensorflow-2.16.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached tensorflow-2.16.1-cp312-cp312-win_amd64.whl.metadata (3.5 kB)\n",
      "Collecting keras>=2.2.0 (from deepface)\n",
      "  Obtaining dependency information for keras>=2.2.0 from https://files.pythonhosted.org/packages/8d/44/c604ecc5c9993b6574a681f2f505e980725871a89cfd9e48597b12ccb506/keras-3.3.3-py3-none-any.whl.metadata\n",
      "  Using cached keras-3.3.3-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting Flask>=1.1.2 (from deepface)\n",
      "  Obtaining dependency information for Flask>=1.1.2 from https://files.pythonhosted.org/packages/61/80/ffe1da13ad9300f87c93af113edd0638c75138c42a0994becfacac078c06/flask-3.0.3-py3-none-any.whl.metadata\n",
      "  Using cached flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting mtcnn>=0.1.0 (from deepface)\n",
      "  Obtaining dependency information for mtcnn>=0.1.0 from https://files.pythonhosted.org/packages/09/d1/2a4269e387edb97484157b872fa8a1953b53dcafbe4842a1967f549ac5ea/mtcnn-0.1.1-py3-none-any.whl.metadata\n",
      "  Using cached mtcnn-0.1.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting retina-face>=0.0.1 (from deepface)\n",
      "  Obtaining dependency information for retina-face>=0.0.1 from https://files.pythonhosted.org/packages/84/87/30c5beef6ef3cb60f80f02d3f934b86efda21aca3225f174d127192d43bb/retina_face-0.0.17-py3-none-any.whl.metadata\n",
      "  Using cached retina_face-0.0.17-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting fire>=0.4.0 (from deepface)\n",
      "  Using cached fire-0.6.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: gunicorn>=20.1.0 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from deepface) (22.0.0)\n",
      "Requirement already satisfied: six in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from fire>=0.4.0->deepface) (1.16.0)\n",
      "Requirement already satisfied: termcolor in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from fire>=0.4.0->deepface) (2.4.0)\n",
      "Collecting Werkzeug>=3.0.0 (from Flask>=1.1.2->deepface)\n",
      "  Obtaining dependency information for Werkzeug>=3.0.0 from https://files.pythonhosted.org/packages/9d/6e/e792999e816d19d7fcbfa94c730936750036d65656a76a5a688b57a656c4/werkzeug-3.0.3-py3-none-any.whl.metadata\n",
      "  Using cached werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting Jinja2>=3.1.2 (from Flask>=1.1.2->deepface)\n",
      "  Obtaining dependency information for Jinja2>=3.1.2 from https://files.pythonhosted.org/packages/31/80/3a54838c3fb461f6fec263ebf3a3a41771bd05190238de3486aae8540c36/jinja2-3.1.4-py3-none-any.whl.metadata\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from Flask>=1.1.2->deepface) (2.2.0)\n",
      "Collecting click>=8.1.3 (from Flask>=1.1.2->deepface)\n",
      "  Obtaining dependency information for click>=8.1.3 from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting blinker>=1.6.2 (from Flask>=1.1.2->deepface)\n",
      "  Obtaining dependency information for blinker>=1.6.2 from https://files.pythonhosted.org/packages/bb/2a/10164ed1f31196a2f7f3799368a821765c62851ead0e630ab52b8e14b4d0/blinker-1.8.2-py3-none-any.whl.metadata\n",
      "  Using cached blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting beautifulsoup4 (from gdown>=3.10.1->deepface)\n",
      "  Obtaining dependency information for beautifulsoup4 from https://files.pythonhosted.org/packages/b1/fe/e8c672695b37eecc5cbf43e1d0638d88d66ba3a44c4d321c796f4e59167f/beautifulsoup4-4.12.3-py3-none-any.whl.metadata\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting filelock (from gdown>=3.10.1->deepface)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/41/24/0b023b6537dfc9bae2c779353998e3e99ac7dfff4222fc6126650e93c3f3/filelock-3.14.0-py3-none-any.whl.metadata\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: packaging in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from gunicorn>=20.1.0->deepface) (24.0)\n",
      "Collecting absl-py (from keras>=2.2.0->deepface)\n",
      "  Obtaining dependency information for absl-py from https://files.pythonhosted.org/packages/a2/ad/e0d3c824784ff121c03cc031f944bc7e139a8f1870ffd2845cc2dd76f6c4/absl_py-2.1.0-py3-none-any.whl.metadata\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=2.2.0->deepface)\n",
      "  Obtaining dependency information for rich from https://files.pythonhosted.org/packages/87/67/a37f6214d0e9fe57f6ae54b2956d550ca8365857f42a1ce0392bb21d9410/rich-13.7.1-py3-none-any.whl.metadata\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: namex in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from keras>=2.2.0->deepface) (0.0.8)\n",
      "Requirement already satisfied: h5py in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from keras>=2.2.0->deepface) (3.11.0)\n",
      "Collecting optree (from keras>=2.2.0->deepface)\n",
      "  Obtaining dependency information for optree from https://files.pythonhosted.org/packages/8d/d6/8fbe48f9a022cd58926be69a5e8a6c2b96b7206f2bd722116b37d334bb50/optree-0.11.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached optree-0.11.0-cp312-cp312-win_amd64.whl.metadata (46 kB)\n",
      "Requirement already satisfied: ml-dtypes in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from keras>=2.2.0->deepface) (0.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from pandas>=0.23.4->deepface) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from pandas>=0.23.4->deepface) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from pandas>=0.23.4->deepface) (2024.1)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.27.1->deepface)\n",
      "  Obtaining dependency information for charset-normalizer<4,>=2 from https://files.pythonhosted.org/packages/b6/7c/8debebb4f90174074b827c63242c23851bdf00a532489fba57fef3416e40/charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from requests>=2.27.1->deepface) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from requests>=2.27.1->deepface) (2.2.1)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.27.1->deepface)\n",
      "  Obtaining dependency information for certifi>=2017.4.17 from https://files.pythonhosted.org/packages/ba/06/a07f096c664aeb9f01624f858c3add0a4e913d6c96257acb4fce61e7de14/certifi-2024.2.2-py3-none-any.whl.metadata\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting tensorflow-intel==2.16.1 (from tensorflow>=1.9.0->deepface)\n",
      "  Obtaining dependency information for tensorflow-intel==2.16.1 from https://files.pythonhosted.org/packages/14/5a/0e2c734acb91d22fa67ccb7f0cc869e24c418486aaba3d7ca8cad158d5a0/tensorflow_intel-2.16.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached tensorflow_intel-2.16.1-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface)\n",
      "  Obtaining dependency information for astunparse>=1.6.0 from https://files.pythonhosted.org/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl.metadata\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (24.3.25)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface)\n",
      "  Obtaining dependency information for gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 from https://files.pythonhosted.org/packages/fa/39/5aae571e5a5f4de9c3445dae08a530498e5c53b0e74410eeeb0991c79047/gast-0.5.4-py3-none-any.whl.metadata\n",
      "  Using cached gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (4.25.3)\n",
      "Requirement already satisfied: setuptools in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (69.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (1.63.0)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface)\n",
      "  Obtaining dependency information for tensorboard<2.17,>=2.16 from https://files.pythonhosted.org/packages/3a/d0/b97889ffa769e2d1fdebb632084d5e8b53fc299d43a537acee7ec0c021a3/tensorboard-2.16.2-py3-none-any.whl.metadata\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: colorama in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from tqdm>=4.30.0->deepface) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from Jinja2>=3.1.2->Flask>=1.1.2->deepface) (2.1.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from requests>=2.27.1->deepface) (1.7.1)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=2.2.0->deepface)\n",
      "  Obtaining dependency information for markdown-it-py>=2.2.0 from https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl.metadata\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from rich->keras>=2.2.0->deepface) (2.18.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (0.43.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface) (0.1.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow>=1.9.0->deepface) (0.7.2)\n",
      "Using cached deepface-0.0.91-py3-none-any.whl (97 kB)\n",
      "Using cached flask-3.0.3-py3-none-any.whl (101 kB)\n",
      "Using cached gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Using cached keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
      "Using cached mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
      "Using cached pandas-2.2.2-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached retina_face-0.0.17-py3-none-any.whl (25 kB)\n",
      "Using cached tensorflow-2.16.1-cp312-cp312-win_amd64.whl (2.1 kB)\n",
      "Using cached tensorflow_intel-2.16.1-cp312-cp312-win_amd64.whl (377.1 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp312-cp312-win_amd64.whl (100 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Using cached optree-0.11.0-cp312-cp312-win_amd64.whl (241 kB)\n",
      "Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Installing collected packages: Werkzeug, optree, markdown-it-py, Jinja2, gast, fire, filelock, click, charset-normalizer, certifi, blinker, beautifulsoup4, astunparse, absl-py, tensorboard, rich, requests, pandas, Flask, keras, tensorflow-intel, mtcnn, gdown, tensorflow, retina-face, deepface\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'E:\\\\Basim\\\\GIKI\\\\6th Semester\\\\CS 354 Deep Learning\\\\Project\\\\myenv\\\\Lib\\\\site-packages\\\\pandas\\\\tests\\\\io\\\\excel\\\\test_odf.py'\n",
      "Check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (3.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in e:\\basim\\giki\\6th semester\\cs 354 deep learning\\project\\myenv\\lib\\site-packages (10.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python-headless\n",
    "!pip install retinaface\n",
    "!pip install deepface\n",
    "!pip install matplotlib\n",
    "!pip install pillow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install Necessary Dependencies\n",
    "\n",
    "#### Why are we installing dependencies?\n",
    "- **Explanation**: Before running any code, we need to ensure that all required libraries are installed. These libraries contain pre-written code that we will utilize to implement our face recognition system.\n",
    "\n",
    "#### What are these dependencies and why do we need them?\n",
    "- **Explanation**: The listed dependencies are Python packages that provide functionality for image processing, face detection, and deep learning-based face recognition. Each library serves a specific purpose in our system.\n",
    "\n",
    "#### What is the significance of each dependency?\n",
    "- **Explanation**:\n",
    "  - `opencv-python-headless`: OpenCV (Open Source Computer Vision Library) is a popular library for image and video processing. Here, we install the headless version, which doesn't require a graphical user interface (GUI) and is suitable for server-side applications.\n",
    "  - `retinaface`: This library provides a face detection model based on the RetinaFace algorithm. Face detection is the process of identifying and localizing human faces within an image.\n",
    "  - `deepface`: DeepFace is a deep learning-based face recognition library. It provides pre-trained models and methods for face recognition tasks.\n",
    "  - `matplotlib`: Matplotlib is a plotting library in Python. Although not directly related to face recognition, we'll use it to visualize our results, such as displaying the labeled images.\n",
    "  - `pillow`: Pillow is an image processing library that provides functionality for opening, manipulating, and saving many different image file formats.\n",
    "\n",
    "#### How do we install these dependencies?\n",
    "- **Explanation**: We use the `pip` package manager to install Python packages from the Python Package Index (PyPI). By running `!pip install` followed by the package names, we instruct `pip` to download and install the specified packages and their dependencies.\n",
    "\n",
    "#### Why do we use `!pip` in a Jupyter notebook?\n",
    "- **Explanation**: In a Jupyter notebook, lines beginning with `!` are interpreted as shell commands rather than Python code. By using `!pip`, we execute the `pip` command within the notebook environment to install the required packages.\n",
    "\n",
    "#### Why do we need to install these dependencies before running the code?\n",
    "- **Explanation**: Without these dependencies, our code would be unable to perform the necessary image processing, face detection, and face recognition tasks. Installing the dependencies ensures that our code has access to the required functionality.\n",
    "\n",
    "By understanding the purpose and significance of each dependency, even someone new to AI or deep learning can grasp the importance of installing these libraries before proceeding with the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbase64\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import re\n",
    "import base64\n",
    "import numpy as np\n",
    "from retinaface import RetinaFace\n",
    "from deepface import DeepFace\n",
    "from PIL import Image\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import Necessary Libraries\n",
    "\n",
    "#### Purpose of Importing Libraries:\n",
    "- In Python, libraries extend the language's functionality, providing pre-written code for various tasks.\n",
    "- By importing libraries, we gain access to tools and functions that simplify our coding tasks.\n",
    "\n",
    "#### Libraries and Their Significance in Our Project:\n",
    "- `os`: Facilitates interaction with the operating system, allowing file and directory operations crucial for managing images and directories.\n",
    "- `cv2`: Provides essential functions for image processing and computer vision tasks, such as reading, writing, and manipulating images, which are fundamental for our face recognition system.\n",
    "- `re`: Enables pattern matching and string manipulation using regular expressions, aiding in extracting person names from file paths.\n",
    "- `base64`: Essential for encoding images as base64 strings, enabling efficient transfer of image data, which is useful for displaying images in web applications or transferring images over networks.\n",
    "- `numpy`: Facilitates numerical computing with arrays and matrices, crucial for performing mathematical operations on images and data, such as resizing images or performing matrix calculations in deep learning models.\n",
    "- `RetinaFace`: Provides accurate face detection capabilities based on the RetinaFace algorithm, allowing us to precisely locate faces within images, which is the initial step in our face recognition process.\n",
    "- `DeepFace`: Offers deep learning-based face recognition capabilities, allowing us to recognize faces in images and perform related tasks, such as labeling detected faces with corresponding names.\n",
    "- `Image` (from PIL): Provides tools for opening, manipulating, and saving various image file formats, which are essential for handling image data in our project.\n",
    "- `io`: Handles input and output operations, particularly with binary data streams, facilitating the reading and writing of image data, which is crucial for processing images in our project.\n",
    "- `matplotlib.pyplot`: Enables creation of visualizations, such as displaying images and plots, which is useful for visualizing our face recognition results and evaluating the performance of our system.\n",
    "\n",
    "#### Usage of Libraries:\n",
    "- Libraries are imported using the `import` statement, followed by the library name or specific module within the library.\n",
    "- Each library plays a critical role in our face recognition project, contributing specific functionality necessary for tasks such as image processing, face detection, face recognition, and visualization.\n",
    "- Together, these libraries form the foundation of our project, providing the tools and capabilities required to build an effective face recognition system.\n",
    "\n",
    "Understanding the role of each library in our project provides insight into how these tools are utilized to achieve our goals, emphasizing their significance in the context of our face recognition implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, new_width=None, new_height=None):\n",
    "    (height, width) = image.shape[:2]\n",
    "    \n",
    "    if new_width is None and new_height is None:\n",
    "        return image\n",
    "\n",
    "    if new_width is not None:\n",
    "        ratio = new_width / float(width)\n",
    "        new_height = int(height * ratio)\n",
    "    else:\n",
    "        ratio = new_height / float(height)\n",
    "        new_width = int(width * ratio)\n",
    "\n",
    "    resized_image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "    return resized_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize Image Function:\n",
    "\n",
    "#### Purpose:\n",
    "- The resize_image function is designed to resize an input image while preserving its aspect ratio.\n",
    "\n",
    "#### Function Signature:\n",
    "```python\n",
    "def resize_image(image, new_width=None, new_height=None):\n",
    "```\n",
    "\n",
    "#### Parameters:\n",
    "- `image`: The input image to be resized.\n",
    "- `new_width`: The desired width of the resized image.\n",
    "- `new_height`: The desired height of the resized image.\n",
    "\n",
    "#### Function Logic:\n",
    "1. **Aspect Ratio Calculation**: \n",
    "   - If both `new_width` and `new_height` are provided, the function calculates the aspect ratio using the provided dimensions.\n",
    "   - If only one dimension is provided (`new_width` or `new_height`), the function calculates the other dimension to maintain the original aspect ratio of the image.\n",
    "\n",
    "2. **Resizing Operation**:\n",
    "   - The function utilizes OpenCV's `cv2.resize` function to resize the image efficiently while preserving the aspect ratio, ensuring that the resized image retains the original content.\n",
    "\n",
    "#### Significance:\n",
    "- Resizing images is a fundamental preprocessing step in computer vision tasks.\n",
    "- Maintaining the aspect ratio during resizing prevents distortion and preserves the original content of the image.\n",
    "- The resize_image function provides a convenient way to resize images to desired dimensions, facilitating consistent processing and analysis in our face recognition system.\n",
    "\n",
    "#### Example Usage:\n",
    "```python\n",
    "# Resize an image to a specific width\n",
    "resized_image = resize_image(image, new_width=300)\n",
    "\n",
    "# Resize an image to a specific height\n",
    "resized_image = resize_image(image, new_height=200)\n",
    "\n",
    "# Resize an image to specific width and height\n",
    "resized_image = resize_image(image, new_width=300, new_height=200)\n",
    "```\n",
    "\n",
    "#### Summary:\n",
    "- The resize_image function plays a crucial role in our face recognition system by resizing images to desired dimensions.\n",
    "- Leveraging the OpenCV library, the function efficiently performs the resizing operation, contributing to the overall effectiveness and performance of our face recognition system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_faces(image, db_path=\"class_db2\"):\n",
    "    tmpImage = image.copy()\n",
    "    peopleFound = set()\n",
    "    faces = RetinaFace.detect_faces(image)\n",
    "    \n",
    "    thickness = round(2 / 1500 * image.shape[0])\n",
    "    fontscale = 0.9 / 2000 * image.shape[0]\n",
    "    \n",
    "    for face in faces.values():\n",
    "        x1, y1, x2, y2 = face[\"facial_area\"]\n",
    "        x = x1\n",
    "        y = y1\n",
    "        w = x2 - x1\n",
    "        h = y2 - y1\n",
    "        personImage = image[y:y+h, x:x+w].copy()\n",
    "        \n",
    "        dfs = DeepFace.find(\n",
    "            img_path=personImage,\n",
    "            db_path=db_path,\n",
    "            silent=True,\n",
    "            enforce_detection=False\n",
    "        )\n",
    "        \n",
    "        personPredictions = dfs[0][\"identity\"]\n",
    "        notPredicted = personPredictions.shape[0] == 0\n",
    "        if notPredicted:\n",
    "            personName = \"Unknown\"\n",
    "        else:\n",
    "            personName = re.split(r\"[\\\\.]\", dfs[0][\"identity\"][0])[1]\n",
    "            peopleFound.add(personName)\n",
    "\n",
    "        cv2.rectangle(tmpImage, (x, y), (x + w, y + h), (0, 255, 0), thickness)\n",
    "        cv2.putText(\n",
    "            tmpImage,\n",
    "            f\"{personName}\",\n",
    "            (x, y - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            fontscale,\n",
    "            (0, 255, 0),\n",
    "            thickness\n",
    "        )\n",
    "    \n",
    "    return tmpImage, peopleFound\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Faces Function:\n",
    "\n",
    "#### Purpose:\n",
    "- The `label_faces` function is responsible for detecting faces in an input image and labeling them with corresponding names using deep learning-based face recognition.\n",
    "\n",
    "#### Function Signature:\n",
    "```python\n",
    "def label_faces(image, db_path=\"class_db2\"):\n",
    "```\n",
    "\n",
    "#### Parameters:\n",
    "- `image`: The input image in which faces are to be detected and labeled.\n",
    "- `db_path`: The path to the database containing reference images of known faces for recognition.\n",
    "\n",
    "#### Function Logic:\n",
    "1. **Initialization**:\n",
    "   - Create a copy of the input image to avoid modifying the original image.\n",
    "   - Initialize an empty set to store the names of people found in the image.\n",
    "\n",
    "2. **Face Detection**:\n",
    "   - Use the RetinaFace algorithm to detect faces in the input image.\n",
    "   - Retrieve the coordinates of the detected facial areas (bounding boxes).\n",
    "\n",
    "3. **Face Recognition**:\n",
    "   - Iterate through each detected face.\n",
    "   - Extract the facial region from the image.\n",
    "   - Use the DeepFace library to recognize the face by comparing it with reference images in the provided database.\n",
    "   - If a match is found, extract the person's name from the recognition result. Otherwise, label the face as \"Unknown\".\n",
    "\n",
    "4. **Drawing Boxes and Labels**:\n",
    "   - Draw rectangles around the detected faces on the copied image.\n",
    "   - Label each face with the corresponding person's name or \"Unknown\".\n",
    "\n",
    "5. **Return Results**:\n",
    "   - Return the labeled image and the set of names of people found in the image.\n",
    "\n",
    "#### Libraries Used:\n",
    "- `RetinaFace`: Utilized for accurate face detection.\n",
    "  - The `detect_faces` function from RetinaFace is used to detect faces in the input image.\n",
    "- `DeepFace`: Employed for deep learning-based face recognition.\n",
    "  - The `find` function from DeepFace is used to recognize faces by comparing them with reference images in the provided database.\n",
    "- `cv2`: Utilized for drawing rectangles and text on the image.\n",
    "  - Functions like `cv2.rectangle` and `cv2.putText` from OpenCV are used to draw rectangles around detected faces and label them with corresponding names.\n",
    "\n",
    "#### Significance:\n",
    "- Accurate face detection and recognition are crucial for the functionality of a face recognition system.\n",
    "- The RetinaFace algorithm ensures robust face detection, even in challenging conditions.\n",
    "- DeepFace provides state-of-the-art face recognition capabilities, enabling accurate recognition of known individuals.\n",
    "- Drawing rectangles and labels on the image visually communicates the results of face detection and recognition to the user.\n",
    "\n",
    "#### Example Usage:\n",
    "```python\n",
    "# Detect and label faces in an image\n",
    "labeled_image, people_found = label_faces(image, db_path=\"class_db2\")\n",
    "```\n",
    "\n",
    "#### Summary:\n",
    "- The `label_faces` function integrates face detection and recognition capabilities to detect and label faces in an input image.\n",
    "- Leveraging the RetinaFace and DeepFace libraries, it achieves accurate face detection and recognition, contributing to the effectiveness of our face recognition system.\n",
    "- Drawing rectangles and labels on the image enhances the interpretability of the results, enabling users to identify recognized individuals in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        img_bytes = f.read()\n",
    "    image_base64 = base64.b64encode(img_bytes).decode('utf-8')\n",
    "    return image_base64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Image to Base64 Function:\n",
    "\n",
    "#### Purpose:\n",
    "- The `encode_image_to_base64` function is designed to encode an image file as a base64 string.\n",
    "\n",
    "#### Function Signature:\n",
    "```python\n",
    "def encode_image_to_base64(image_path):\n",
    "```\n",
    "\n",
    "#### Parameters:\n",
    "- `image_path`: The path to the image file to be encoded.\n",
    "\n",
    "#### Function Logic:\n",
    "1. **Reading Image Bytes**:\n",
    "   - Open the image file in binary mode (`\"rb\"`).\n",
    "   - Read the binary data of the image file and store it in `img_bytes`.\n",
    "\n",
    "2. **Encoding as Base64**:\n",
    "   - Use the `base64.b64encode` function to encode the binary image data (`img_bytes`) as a base64-encoded string.\n",
    "   - Decode the resulting bytes to a UTF-8 string to obtain the base64 string representation (`image_base64`).\n",
    "\n",
    "3. **Return Base64 String**:\n",
    "   - Return the base64-encoded string representing the image.\n",
    "\n",
    "#### Libraries Used:\n",
    "- `base64`: Utilized for encoding binary data as base64 strings.\n",
    "  - The `b64encode` function from the base64 library is used to perform the base64 encoding.\n",
    "\n",
    "#### Significance:\n",
    "- Base64 encoding is commonly used for transferring binary data, such as images, in text-based formats, such as JSON or XML.\n",
    "- Encoding images as base64 strings allows them to be embedded directly into HTML, CSS, or JSON responses in web applications.\n",
    "- This function facilitates the conversion of image files to a format suitable for transfer over networks or inclusion in data payloads.\n",
    "\n",
    "#### Example Usage:\n",
    "```python\n",
    "# Encode an image file as base64\n",
    "encoded_image = encode_image_to_base64(\"image.jpg\")\n",
    "```\n",
    "\n",
    "#### Summary:\n",
    "- The `encode_image_to_base64` function converts an image file into a base64-encoded string, enabling its representation in a text-based format.\n",
    "- By leveraging the base64 library, it efficiently performs the encoding operation, ensuring compatibility with various data transfer protocols and formats.\n",
    "- This function plays a crucial role in our project by facilitating the transfer and representation of image data in contexts where binary data is not directly supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_label_image(image_path, db_parent_folder):\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    if img.shape[1] > 1920:\n",
    "        img = resize_image(img, new_width=1920)\n",
    "    \n",
    "    original_folder = os.getcwd()\n",
    "    os.chdir(db_parent_folder)\n",
    "    img, labels = label_faces(img)\n",
    "    os.chdir(original_folder)\n",
    "    \n",
    "    labeled_save_path = \".\".join(image_path.split(\".\")[:-1]) + \"_labeled.\" + image_path.split(\".\")[-1]\n",
    "    cv2.imwrite(labeled_save_path, img)\n",
    "    \n",
    "    image_base64 = encode_image_to_base64(labeled_save_path)\n",
    "    \n",
    "    return labeled_save_path, labels, image_base64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process and Label Image Function:\n",
    "\n",
    "#### Purpose:\n",
    "- The `process_and_label_image` function serves to process an image, label faces within it, and encode the labeled image as a base64 string.\n",
    "\n",
    "#### Function Signature:\n",
    "```python\n",
    "def process_and_label_image(image_path, db_parent_folder):\n",
    "```\n",
    "\n",
    "#### Parameters:\n",
    "- `image_path`: The path to the image file to be processed and labeled.\n",
    "- `db_parent_folder`: The parent folder containing the database of known faces for recognition.\n",
    "\n",
    "#### Function Logic:\n",
    "1. **Read Image**:\n",
    "   - Load the image from the specified `image_path` using OpenCV's `cv2.imread` function.\n",
    "\n",
    "2. **Resize Image**:\n",
    "   - If the width of the loaded image exceeds 1920 pixels, resize the image to ensure it fits within this constraint.\n",
    "\n",
    "3. **Label Faces**:\n",
    "   - Change the current directory to the parent folder containing the database (`db_parent_folder`).\n",
    "   - Call the `label_faces` function to detect and label faces within the image.\n",
    "   - Retrieve the labeled image and the set of labels (names of people found in the image).\n",
    "\n",
    "4. **Save Labeled Image**:\n",
    "   - Generate a file path for the labeled image by appending \"_labeled\" to the original image file name.\n",
    "   - Save the labeled image to the specified path using OpenCV's `cv2.imwrite` function.\n",
    "\n",
    "5. **Encode Labeled Image as Base64**:\n",
    "   - Encode the labeled image as a base64 string using the `encode_image_to_base64` function.\n",
    "\n",
    "6. **Return Results**:\n",
    "   - Return the path to the labeled image file, the set of labels (names of people found in the image), and the base64-encoded string representing the labeled image.\n",
    "\n",
    "#### Libraries Used:\n",
    "- `cv2`: Utilized for reading and writing images, as well as resizing them.\n",
    "- `os`: Used for navigating the file system and changing directories.\n",
    "- `label_faces`: Called to detect and label faces within the image.\n",
    "- `encode_image_to_base64`: Invoked to encode the labeled image as a base64 string.\n",
    "\n",
    "#### Significance:\n",
    "- This function automates the process of processing and labeling images, providing a convenient way to analyze images and recognize faces within them.\n",
    "- By leveraging existing functions for face detection, labeling, and base64 encoding, it encapsulates complex operations into a single coherent workflow.\n",
    "\n",
    "#### Example Usage:\n",
    "```python\n",
    "# Process and label an image\n",
    "labeled_image_path, labels, image_base64 = process_and_label_image(\"image.jpg\", \"database_folder\")\n",
    "```\n",
    "\n",
    "#### Summary:\n",
    "- The `process_and_label_image` function combines image processing, face labeling, and base64 encoding to analyze and label faces within an image.\n",
    "- By orchestrating these operations, it streamlines the process of image analysis and enables seamless integration with other components of the face recognition system.\n",
    "- This function enhances the functionality and usability of the face recognition system by providing a high-level interface for processing and labeling images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'path/to/your/image.jpg'  # Replace with the path to your image\n",
    "db_parent_folder = 'path/to/class_db2'  # Replace with the path to your database folder\n",
    "\n",
    "labeled_save_path, labels, image_base64 = process_and_label_image(image_path, db_parent_folder)\n",
    "\n",
    "print(f\"Labeled image saved at: {labeled_save_path}\")\n",
    "print(f\"Labels found: {labels}\")\n",
    "\n",
    "# Display the labeled image\n",
    "labeled_image = cv2.imread(labeled_save_path)\n",
    "plt.imshow(cv2.cvtColor(labeled_image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Purpose:\n",
    "- The code block demonstrates how to utilize the `process_and_label_image` function to process an image, label faces within it, and display the labeled image.\n",
    "\n",
    "#### Variables:\n",
    "- `image_path`: Path to the image file to be processed and labeled.\n",
    "- `db_parent_folder`: Path to the parent folder containing the database of known faces for recognition.\n",
    "\n",
    "#### Function Call:\n",
    "- `process_and_label_image`: Calls the function to process and label the image specified by `image_path` using the database located in `db_parent_folder`.\n",
    "- The function returns the path to the labeled image file (`labeled_save_path`), the set of labels (names of people found in the image) (`labels`), and the base64-encoded string representing the labeled image (`image_base64`).\n",
    "\n",
    "#### Displaying Results:\n",
    "- Prints the path to the saved labeled image (`labeled_save_path`) and the labels found in the image (`labels`).\n",
    "- Reads the labeled image using OpenCV's `cv2.imread` function.\n",
    "- Converts the color space of the image from BGR to RGB using `cv2.cvtColor`.\n",
    "- Displays the labeled image using Matplotlib's `plt.imshow` function.\n",
    "- Turns off the axis display using `plt.axis('off')` to remove axis labels.\n",
    "\n",
    "#### Libraries Used:\n",
    "- `cv2`: Utilized for reading images and converting color spaces.\n",
    "- `matplotlib.pyplot` (imported as `plt`): Used for displaying images.\n",
    "- `process_and_label_image`: Invoked to process and label the input image.\n",
    "- Other standard libraries such as `os` and `base64` are indirectly used through the `process_and_label_image` function.\n",
    "\n",
    "#### Significance:\n",
    "- This code block demonstrates how to use the `process_and_label_image` function to automate the process of image processing and face labeling.\n",
    "- It provides a clear and concise way to analyze images and recognize faces within them, enabling efficient utilization of the face recognition system.\n",
    "\n",
    "#### Example Usage:\n",
    "```python\n",
    "# Define image path and database folder path\n",
    "image_path = 'path/to/your/image.jpg'\n",
    "db_parent_folder = 'path/to/class_db2'\n",
    "\n",
    "# Process and label the image\n",
    "labeled_save_path, labels, image_base64 = process_and_label_image(image_path, db_parent_folder)\n",
    "\n",
    "# Print results\n",
    "print(f\"Labeled image saved at: {labeled_save_path}\")\n",
    "print(f\"Labels found: {labels}\")\n",
    "\n",
    "# Display the labeled image\n",
    "labeled_image = cv2.imread(labeled_save_path)\n",
    "plt.imshow(cv2.cvtColor(labeled_image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### Summary:\n",
    "- This code block showcases the practical usage of the `process_and_label_image` function in a real-world scenario.\n",
    "- It demonstrates how to process images, detect faces, label them, and visualize the results in a user-friendly manner using Python libraries such as OpenCV and Matplotlib."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
